---
title: "Kaggle Toxic Comments - Piotr"
output: html_notebook
---

```{r setup}
library(dplyr)
library(tidytext)
library(tm)
library(sentimentr)
library(ggplot2)
```


Load the data

```{r}
train_set <- read.csv("../data/train.csv", stringsAsFactors = FALSE)
test_set <- read.csv("../data/test.csv", stringsAsFactors = FALSE)

head(train_set)
```

Create corpus and document term matrix

```{r}
train_corpus <- SimpleCorpus(VectorSource(train_set$comment_text),
                             control = list(language = "en"))

train_dtm <- DocumentTermMatrix(train_corpus, control = list(tokenize = "words",
                                                             tolower = TRUE,
                                                             removePunctuation = TRUE,
                                                             removeNumbers = TRUE,
                                                             stopwords = TRUE))

inspect(train_dtm)
```

Let's illustrate differences between all six different types of comments.

Group documents by category first.

```{r}
# First tidy the DTM
train_t <- tidy(train_dtm)

# Which documents are classified as toxic, severe toxic, etc.
bad_comments <- lapply(train_set[, 3:8], function(x) (1:length(x))[x == 1])

# Summarise term frequency for each type of comment
term_freqs <- lapply(bad_comments, function(x) { 
  filter(train_t, document %in% x) %>%
  group_by(term) %>%
  summarise(count = sum(count))
})

# Add column with document name (toxic, severe toxic etc.)
term_freqs <- lapply(names(term_freqs), function(x) mutate(term_freqs[[x]], document = x))

# Cast into DTM with summarised document types
bad_docs <- cast_dtm(bind_rows(term_freqs), document, term, count)

inspect(bad_docs)
```

Now create comparison wordcloud!

```{r fig.width=10, fig.height=8}
wordcloud::comparison.cloud(as.matrix(as.TermDocumentMatrix(bad_docs)), max.words = 200)
```

Seems like there is quite a bit lot of overlap for "obscene", "insult" and "toxic" categories 
as they do not have very distinctive words associated with them.

So how often do comments classified as one type get classified as other types?

```{r}
# Percentage of each comment class that gets classfied as also another class
other_class <- lapply(3:8, function(x) colMeans(train_set[train_set[[x]] == 1, 3:8]))
names(other_class) <- names(train_set[, 3:8])

# Now into long data frame
other_class <- tibble::rownames_to_column(as.data.frame(other_class), "other_class")
other_class <- tidyr::gather(other_class, "type", "percentage", -other_class)

head(other_class)
```

And now plot!

```{r fig.width=8, fig.height=4.5}
filter(other_class, other_class != type) %>%
  ggplot(aes(x = other_class, y = percentage, fill = other_class)) + facet_wrap(~ type, ncol = 3) + geom_col() +
  theme_bw() + scale_y_continuous(labels = scales::percent) + scale_fill_brewer(palette = "BrBG") + 
  labs(fill = "Other class", x = NULL, y = "Percentage of comments that have other classification") +
  theme(axis.text.x = element_blank())

```

So it seems that any comment that falls into category other than "toxic" is also a "toxic" comment.
The reverse however does not seem to be true. "Toxic" appears to be a catch-all term.

# How are different types of comments correlated

```{r}
train_bad <- train_set[rowSums(train_set[, 3:8]) > 0, 3:8]
corrplot::corrplot(cor(train_bad))
```

How are comments similar?

```{r}
plot(hclust(dist(cor(train_bad))), main = "Comment types", sub = "", xlab = "")
```

